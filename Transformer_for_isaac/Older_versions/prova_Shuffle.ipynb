{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.graph_objects as go\n",
    "from transformer_sim import Config, TSTransformer\n",
    "#import tqdm\n",
    "import argparse\n",
    "import metrics\n",
    "import os   \n",
    "\n",
    "fig_path = Path(\"fig\")\n",
    "fig_path.mkdir(exist_ok=True)\n",
    "\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(430)\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(430)\n",
    "\n",
    "# Overall settings\n",
    "out_dir = \"out\"\n",
    "# System settings\n",
    "nu = 7\n",
    "ny = 14\n",
    "batch_size = 32 # 256\n",
    "\n",
    "# Compute settings\n",
    "cuda_device = \"cuda:0\"\n",
    "no_cuda = False\n",
    "threads = 5\n",
    "compile = False \n",
    "\n",
    "# Configure compute\n",
    "torch.set_num_threads(threads) \n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device_name  = cuda_device if use_cuda else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "device_type = 'cuda' if 'cuda' in device_name else 'cpu' # for later use in torch.autocast\n",
    "# torch.set_float32_matmul_precision(\"high\") \n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 available files in /home/manuel/isaacgym/python/examples/Franka/out_tensors/train:\n",
      "\n",
      " -->  672_envs_4022_steps_1000_f_0_2_MS_rand_1010_bounds_mass_10_10.pt\n",
      " -->  881_envs_4029_steps_1000_f_0_15_MS_rand_1010_bounds_mass_15_15.pt\n",
      " -->  205_envs_4035_steps_1000_f_0_15_MS_rand_1010_bounds_mass_10_10.pt\n",
      " -->  475_envs_4022_steps_1000_f_0_2_MS_rand_1010_bounds_mass_15_15.pt\n",
      " -->  113_envs_4016_steps_1000_f_0_2_MS_rand_1010_bounds_mass_5_5.pt\n",
      " -->  11_envs_4037_steps_1000_f_0_1_MS_rand_1010_bounds_mass_5_5.pt\n",
      " -->  842_envs_4053_steps_1000_f_0_1_MS_rand_1010_bounds_mass_15_15.pt\n",
      " -->  579_envs_4013_steps_1000_f_0_15_MS_rand_1010_bounds_mass_5_5.pt\n",
      " -->  534_envs_4037_steps_1000_f_0_1_MS_rand_1010_bounds_mass_10_10.pt\n"
     ]
    }
   ],
   "source": [
    "parent_folder = os.path.join(os.getcwd(), os.pardir) \n",
    "parent_folder = os.path.abspath(parent_folder)\n",
    "\n",
    "try:\n",
    "    relative_folder = f\"isaacgym/python/examples/Franka/out_tensors/train\"\n",
    "    tensors_path = os.path.join(parent_folder,relative_folder ) \n",
    "    tensors_path = os.path.abspath(tensors_path)\n",
    "    list_of_available_tensors = os.listdir(tensors_path)\n",
    "except FileNotFoundError:\n",
    "    relative_folder = f\"Data_generation/python/examples/Franka/out_tensors/train\"\n",
    "    tensors_path = os.path.join(parent_folder,relative_folder ) \n",
    "    tensors_path = os.path.abspath(tensors_path)\n",
    "    list_of_available_tensors = os.listdir(tensors_path)\n",
    "\n",
    "tensors_path = os.path.join(parent_folder,relative_folder ) \n",
    "tensors_path = os.path.abspath(tensors_path)\n",
    "directory_available_tensors = os.listdir(tensors_path)\n",
    "\n",
    "print(\"There are \"+str(len(directory_available_tensors)) +\" available files in \"+str(tensors_path) +\":\\n\")\n",
    "\n",
    "list_available_tensors =[]\n",
    "for i in range(len(directory_available_tensors)):\n",
    "    single_pt_file_path = os.path.join(tensors_path, directory_available_tensors[i]) \n",
    "    list_available_tensors.append(directory_available_tensors[i])\n",
    "    print(\" --> \",directory_available_tensors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pt_files = len(directory_available_tensors)\n",
    "tensors_used_for_training = list_available_tensors[0:number_of_pt_files-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-control torch.Size([4022, 1000, 7])\n",
      "single-position torch.Size([4022, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([4022, 1000, 7])\n",
      "total-position torch.Size([4022, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4029, 1000, 7])\n",
      "single-position torch.Size([4029, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([8051, 1000, 7])\n",
      "total-position torch.Size([8051, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4035, 1000, 7])\n",
      "single-position torch.Size([4035, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([12086, 1000, 7])\n",
      "total-position torch.Size([12086, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4022, 1000, 7])\n",
      "single-position torch.Size([4022, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([4022, 1000, 7])\n",
      "total-position torch.Size([4022, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4016, 1000, 7])\n",
      "single-position torch.Size([4016, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([8038, 1000, 7])\n",
      "total-position torch.Size([8038, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4037, 1000, 7])\n",
      "single-position torch.Size([4037, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([12075, 1000, 7])\n",
      "total-position torch.Size([12075, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4053, 1000, 7])\n",
      "single-position torch.Size([4053, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([4053, 1000, 7])\n",
      "total-position torch.Size([4053, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4013, 1000, 7])\n",
      "single-position torch.Size([4013, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([8066, 1000, 7])\n",
      "total-position torch.Size([8066, 1000, 14])\n",
      " ------------------------- \n",
      "\n",
      "single-control torch.Size([4037, 1000, 7])\n",
      "single-position torch.Size([4037, 1000, 14])\n",
      "\n",
      "\n",
      "total-control torch.Size([12103, 1000, 7])\n",
      "total-position torch.Size([12103, 1000, 14])\n",
      " ------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pick_number = 3\n",
    "for i in range(0,number_of_pt_files,pick_number):\n",
    "    # print(\"--------------BIG PICK---------------\")\n",
    "    control_action = torch.zeros(0,1000,7)\n",
    "    position = torch.zeros(0,1000,14)\n",
    "\n",
    "    for j in range(pick_number):\n",
    "        single_pt_file_path = os.path.join(tensors_path, directory_available_tensors[i+j]) \n",
    "        # print(\"\\nStarting with file:\\n\", directory_available_tensors[i+j],\"\\n\")\n",
    "        loaded = torch.load(single_pt_file_path,map_location=device)\n",
    "\n",
    "        def loading():\n",
    "            control_action_extracted = loaded['control_action'][1:,:,:7]\n",
    "            position_extracted = loaded['position']\n",
    "            position = torch.movedim(position_extracted.to('cpu'),-2,-3)\n",
    "            control_action = torch.movedim(control_action_extracted.to('cpu'),-2,-3)\n",
    "            \n",
    "            control_action = control_action[:,:,:7] # first is the number of simulations\n",
    "            position = position[:,:,:]\n",
    "            return control_action,position\n",
    "        \n",
    "        control_action_single,position_single = loading()\n",
    "\n",
    "        control_action = torch.cat((control_action,control_action_single),dim=0)\n",
    "        position = torch.cat((position,position_single),dim=0)\n",
    "        \n",
    "        print(\"single-control\", control_action_single.shape)\n",
    "        print(\"single-position\", position_single.shape)\n",
    "        print(\"\\n\")\n",
    "        print(\"total-control\", control_action.shape)\n",
    "        print(\"total-position\", position.shape)\n",
    "        print(\" ------------------------- \\n\")\n",
    "\n",
    "        dim = 0\n",
    "        idx = torch.randperm(control_action.shape[dim])\n",
    "        # print(idx)\n",
    "        control_action_shuffled = control_action[idx,:,:]\n",
    "        position = position[idx,:,:]\n",
    "    \n",
    "        # print(\"total-control-shuffled\", control_action_shuffled.shape)\n",
    "\n",
    "        # print(control_action[:2,10,:])\n",
    "        # print(control_action_shuffled[:2,10,:])\n",
    "\n",
    "    print(\"i'm training:\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand(2,10,7)\n",
    "# print(a)\n",
    "# dim = 0\n",
    "# idx = torch.randperm(a.shape[dim])\n",
    "# print(\"\\n\")\n",
    "# a = a[idx,:,:]\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm training [0, 1, 2]\n",
      "i'm training [2, 3, 4]\n",
      "i'm training [4, 5, 6]\n",
      "i'm training [6, 7, 8]\n",
      "i'm training [8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "pick = 3\n",
    "for i in range(0,9,2):\n",
    "    # print(i)\n",
    "    control = []\n",
    "    for j in range(pick):\n",
    "        # print(i+j)\n",
    "        control.append(i+j)\n",
    "        \n",
    "    print(\"i'm training\",control)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
